# ğŸ’¹ Financial News Intelligence Agent

Stay ahead of the markets â€” intelligently.

This Streamlit-based app fetches the latest financial headlines, summarizes them using a **local LLM (Mistral via Ollama)**, extracts key financial entities, and analyzes sentiment â€” giving you a fast, AI-powered overview of the financial world.

---

## ğŸš€ Features

- ğŸ“° **Live Financial News Feed** â€” powered by [NewsAPI](https://newsapi.org/)
- ğŸ§  **AI Summarization** â€” local LLM (Mistral via Ollama) generates customizable-length summaries
- ğŸ˜Š **Sentiment Analysis** â€” TextBlob shows how positive, negative, or neutral each article is
- ğŸ·ï¸ **Named Entity Recognition** â€” highlights key financial entities (ORG, MONEY, GPE, etc.)
- ğŸ” **Keyword Filtering** â€” instantly find relevant articles
- ğŸ›ï¸ **Customizable Summary Length** â€” choose between Very Short to Long summaries

---

## ğŸ› ï¸ Tech Stack

| Category            | Tools Used                               |
|---------------------|-------------------------------------------|
| ğŸ§  Language Model    | Mistral (via [Ollama](https://ollama.com/)) |
| ğŸ” Summarization     | LangChain + PromptTemplate + Ollama       |
| ğŸŒ News API          | [NewsAPI.org](https://newsapi.org/)       |
| ğŸ’¬ Sentiment         | TextBlob                                  |
| ğŸ§¾ Entity Extraction | spaCy (NER with `en_core_web_sm`)         |
| ğŸ¨ UI Framework      | Streamlit                                 |

---

## ğŸ§‘â€ğŸ’» Local Setup

> âš ï¸ Requires Ollama installed and Mistral model pulled locally.

### 1. Clone the Repository

git clone https://github.com/yourusername/FinSage.git
cd FinSage

### 2. Set Up a Virtual Environment

python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

### 3. Install Dependencies

pip install -r requirements.txt
python -m spacy download en_core_web_sm

### 4. Add Environment Variables

Create a `.env` file in the root directory and add your NewsAPI key:

NEWSAPI_KEY=your_newsapi_key_here

### 5. Ensure Mistral is Available in Ollama

Make sure Ollama is installed and the Mistral model is running locally:

ollama run mistral

> The app uses LangChain with the local `mistral` model served via Ollama.

### 6. Launch the Streamlit App

streamlit run app.py

---

## ğŸ› ï¸ Optional Tips

- For better Streamlit performance, install the file watcher:

pip install watchdog

- Customize summary lengths and filters easily from the sidebar UI.

---

## ğŸ“„ License

MIT License Â© Sarthak Sukhral

---

## ğŸ¤ Contributing

Contributions are welcome! Please open issues or pull requests for improvements or bug fixes.

---

## ğŸ™ Acknowledgements

- [NewsAPI](https://newsapi.org/) for financial news data  
- [Ollama](https://ollama.com/) and [Mistral](https://mistral.ai/) for local LLM capabilities  
- [LangChain](https://github.com/hwchase17/langchain) for LLM integration  
- [Streamlit](https://streamlit.io/) for app framework  
- [spaCy](https://spacy.io/) for entity extraction

---

